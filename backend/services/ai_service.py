import os
from openai import OpenAI
from typing import Dict, List, Optional
from models.schemas import (
    CatalogInfo, DomainCategory, TableLayer, FieldInfo, SourceTableInfo, 
    CaseAnalysisResponse, AnalysisStep, CaseDecompositionResponse,
    GenerateSQLRequest, GenerateSQLResponse
)
from services.table_service import TableService
import json
import re

class AIService:
    """AIæœåŠ¡ç±»ï¼Œè´Ÿè´£è‡ªåŠ¨ç”Ÿæˆç¼–ç›®ä¿¡æ¯"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è¯»å–OpenAI API Key
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        if not self.openai_api_key:
            print("è­¦å‘Š: OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼ŒAIç¼–ç›®åŠŸèƒ½å°†ä¸å¯ç”¨")
            print("è¯·å‚è€ƒ env_template.txt æ–‡ä»¶é…ç½® OpenAI API Key")
            self.client = None
        else:
            self.client = OpenAI(api_key=self.openai_api_key)
        
        self.table_service = TableService()
    
    def analyze_case(self, case_description: str) -> Optional[CaseAnalysisResponse]:
        """
        åˆ†ææ¡ˆä»¶ç›®æ ‡å¹¶ç”Ÿæˆåˆ†è§£æ­¥éª¤å’ŒSQL
        
        Args:
            case_description: æ¡ˆä»¶ç›®æ ‡æè¿°
            
        Returns:
            CaseAnalysisResponse: åˆ†æç»“æœï¼ŒåŒ…å«æ­¥éª¤å’ŒSQL
        """
        try:
            print(f"ğŸ” å¼€å§‹æ¡ˆä»¶åˆ†è§£: {case_description}")
            
            if not self.client:
                error_msg = "OpenAI API Key æœªé…ç½®ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡"
                print(f"âŒ {error_msg}")
                raise Exception(error_msg)
            
            print("âœ… OpenAIå®¢æˆ·ç«¯å·²å°±ç»ª")
            
            # éªŒè¯API Keyæ ¼å¼
            api_key = os.getenv('OPENAI_API_KEY')
            print(f"ğŸ“‹ ä½¿ç”¨API Key: {api_key[:20]}...")
            
            # æ„å»ºæ¡ˆä»¶åˆ†è§£æç¤ºè¯
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ“…é•¿å¤šæ­¥ä»»åŠ¡åˆ†è§£å’Œç»“æ„åŒ–SQLç”Ÿæˆçš„å¤§æ¨¡å‹åŠæ¡ˆåŠ©æ‰‹ã€‚

è¯·æ ¹æ®ä»¥ä¸‹æ¡ˆä»¶ç›®æ ‡æè¿°ï¼Œè‡ªåŠ¨å®Œæˆé€»è¾‘æ­¥éª¤åˆ†è§£ï¼Œå¹¶é’ˆå¯¹æ¯ä¸ªé€»è¾‘æ­¥éª¤ï¼Œç”Ÿæˆå¯¹åº”çš„SQLè¯­å¥ã€‚

ã€æ¡ˆä»¶ç›®æ ‡æè¿°ã€‘: {case_description}

ã€åˆ†æè¦æ±‚ã€‘ï¼š
1. å°†æ¡ˆä»¶ç›®æ ‡åˆ†è§£ä¸º5-8ä¸ªé€»è¾‘æ­¥éª¤
2. æ¯ä¸ªæ­¥éª¤åº”è¯¥æœ‰æ¸…æ™°çš„é€»è¾‘æè¿°å’Œå¯¹åº”çš„SQLè¯­å¥
3. æ­¥éª¤ä¹‹é—´åº”è¯¥æœ‰é€»è¾‘é€’è¿›å…³ç³»
4. SQLä¸­ä½¿ç”¨ä¼ªå­—æ®µåå’Œä¼ªè¡¨åï¼Œæ–¹ä¾¿åç»­åšå­—æ®µæ›¿æ¢
5. æ—¶é—´æ¡ä»¶è¯·å°½å¯èƒ½ç”¨ NOW() æˆ–è€… DATE_SUB() è¡¨è¾¾
6. æ‰€æœ‰å­—æ®µå°½é‡ä½¿ç”¨è‹±æ–‡åå¹¶æ³¨é‡Šè¯´æ˜å«ä¹‰
7. ä¸å¿…è€ƒè™‘å…·ä½“æ•°æ®åº“ç±»å‹ï¼Œä¿æŒè¯­æ³•é€šç”¨æ€§

è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "summary": "æ¡ˆä»¶åˆ†ææ€»ç»“ï¼Œç®€è¦è¯´æ˜åˆ†ææ€è·¯å’Œç›®æ ‡",
  "steps": [
    {{
      "step_number": 1,
      "description": "æ­¥éª¤1çš„é€»è¾‘æè¿°",
      "sql": "-- æ­¥éª¤1å¯¹åº”çš„SQLä»£ç \\nSELECT..."
    }},
    {{
      "step_number": 2,
      "description": "æ­¥éª¤2çš„é€»è¾‘æè¿°",
      "sql": "-- æ­¥éª¤2å¯¹åº”çš„SQLä»£ç \\nSELECT..."
    }}
  ]
}}

ã€å‚è€ƒç¤ºä¾‹ã€‘ï¼š
æ¡ˆä»¶ç›®æ ‡ï¼šä¹Œé²æœ¨é½ç–‘ä¼¼é«˜é£é™©å·æ¸¡äººå‘˜

åˆ†ææ­¥éª¤ç¤ºä¾‹ï¼š
1. æå–ä¹Œé²æœ¨é½å¸‚å¸¸ä½äººå£ç®¡ç†ä¸­å•ä¸€æ°‘æ—äººå‘˜
2. åŸºäºæ­¥éª¤1ç»“æœæå–æœ€è¿‘ä¸€ä¸ªæœˆå»è¿‡äº‘å—çœçš„äººå‘˜  
3. åŸºäºæ­¥éª¤2ç»“æœï¼Œå…³è”æœ€è¿‘ä¸€ä¸ªæœˆå†…æœ‰äºŒæ‰‹è½¦äº¤æ˜“è¡Œä¸ºçš„äººå‘˜
4. åŸºäºæ­¥éª¤3çš„ç»“æœï¼Œæå–æœ€è¿‘ä¸‰å¹´æœ‰çŠ¯ç½ªè®°å½•çš„äººå‘˜
5. åŸºäºæ­¥éª¤4çš„ç»“æœï¼Œæ ‡æ³¨å‡ºäººå‘˜æˆ·ç±æ‰€å±åŒºå¿

è¯·å‚è€ƒè¿™ä¸ªç¤ºä¾‹çš„åˆ†ææ€è·¯å’Œæ­¥éª¤æ·±åº¦ã€‚"""

            print("ğŸ¤– æ­£åœ¨è°ƒç”¨OpenAI API...")
            
            # è°ƒç”¨OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¡ˆä»¶åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿å°†å¤æ‚æ¡ˆä»¶ç›®æ ‡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„åˆ†ææ­¥éª¤ï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„SQLæŸ¥è¯¢è¯­å¥ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000
            )
            
            print("âœ… OpenAI APIè°ƒç”¨æˆåŠŸ")
            
            ai_response = response.choices[0].message.content
            print(f"ğŸ“ AIå“åº”é•¿åº¦: {len(ai_response)} å­—ç¬¦")
            
            # è§£æAIè¿”å›çš„JSON
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                print("âœ… æ‰¾åˆ°JSONæ ¼å¼å“åº”")
                result = json.loads(json_match.group())
                
                # æ„å»ºåˆ†ææ­¥éª¤
                steps = []
                if 'steps' in result:
                    for step_data in result['steps']:
                        steps.append(AnalysisStep(
                            step_number=step_data.get('step_number', 0),
                            description=step_data.get('description', ''),
                            sql=step_data.get('sql', '')
                        ))
                
                print(f"âœ… æˆåŠŸè§£æ {len(steps)} ä¸ªåˆ†ææ­¥éª¤")
                
                return CaseAnalysisResponse(
                    steps=steps,
                    summary=result.get('summary', 'æ— æ€»ç»“')
                )
            else:
                error_msg = f"AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æJSONã€‚å“åº”å†…å®¹: {ai_response[:500]}..."
                print(f"âŒ {error_msg}")
                return None
                
        except Exception as e:
            error_msg = f"æ¡ˆä»¶åˆ†è§£å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return None
    
    def decompose_case_steps(self, case_description: str) -> Optional[CaseDecompositionResponse]:
        """
        åˆ†ææ¡ˆä»¶ç›®æ ‡å¹¶åˆ†è§£ä¸ºæ­¥éª¤ï¼ˆä¸ç”ŸæˆSQLï¼‰
        
        Args:
            case_description: æ¡ˆä»¶ç›®æ ‡æè¿°
            
        Returns:
            CaseDecompositionResponse: åˆ†è§£çš„æ­¥éª¤
        """
        try:
            print(f"ğŸ” å¼€å§‹æ¡ˆä»¶æ­¥éª¤åˆ†è§£: {case_description}")
            
            if not self.client:
                error_msg = "OpenAI API Key æœªé…ç½®ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡"
                print(f"âŒ {error_msg}")
                raise Exception(error_msg)
            
            print("âœ… OpenAIå®¢æˆ·ç«¯å·²å°±ç»ª")
            
            # æ„å»ºæ­¥éª¤åˆ†è§£æç¤ºè¯
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ“…é•¿å¤šæ­¥ä»»åŠ¡åˆ†è§£çš„å¤§æ¨¡å‹åŠæ¡ˆåŠ©æ‰‹ã€‚

è¯·æ ¹æ®ä»¥ä¸‹æ¡ˆä»¶ç›®æ ‡æè¿°ï¼Œè‡ªåŠ¨å®Œæˆé€»è¾‘æ­¥éª¤åˆ†è§£ã€‚æš‚æ—¶ä¸éœ€è¦ç”ŸæˆSQLã€‚

ã€æ¡ˆä»¶ç›®æ ‡æè¿°ã€‘: {case_description}

ã€åˆ†æè¦æ±‚ã€‘ï¼š
1. å°†æ¡ˆä»¶ç›®æ ‡åˆ†è§£ä¸º5-8ä¸ªé€»è¾‘æ­¥éª¤
2. æ¯ä¸ªæ­¥éª¤åº”è¯¥æœ‰æ¸…æ™°çš„é€»è¾‘æè¿°
3. æ­¥éª¤ä¹‹é—´åº”è¯¥æœ‰é€»è¾‘é€’è¿›å…³ç³»
4. æ­¥éª¤æè¿°åº”è¯¥æ¸…æ™°ã€å…·ä½“ã€å¯æ‰§è¡Œ

è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "summary": "æ¡ˆä»¶åˆ†ææ€»ç»“ï¼Œç®€è¦è¯´æ˜åˆ†ææ€è·¯å’Œç›®æ ‡",
  "steps": [
    {{
      "step_number": 1,
      "description": "æ­¥éª¤1çš„é€»è¾‘æè¿°"
    }},
    {{
      "step_number": 2,
      "description": "æ­¥éª¤2çš„é€»è¾‘æè¿°"
    }}
  ]
}}

ã€å‚è€ƒç¤ºä¾‹ã€‘ï¼š
æ¡ˆä»¶ç›®æ ‡ï¼šä¹Œé²æœ¨é½ç–‘ä¼¼é«˜é£é™©å·æ¸¡äººå‘˜

åˆ†ææ­¥éª¤ç¤ºä¾‹ï¼š
1. æå–ä¹Œé²æœ¨é½å¸‚å¸¸ä½äººå£ç®¡ç†ä¸­å•ä¸€æ°‘æ—äººå‘˜
2. åŸºäºæ­¥éª¤1ç»“æœæå–æœ€è¿‘ä¸€ä¸ªæœˆå»è¿‡äº‘å—çœçš„äººå‘˜  
3. åŸºäºæ­¥éª¤2ç»“æœï¼Œå…³è”æœ€è¿‘ä¸€ä¸ªæœˆå†…æœ‰äºŒæ‰‹è½¦äº¤æ˜“è¡Œä¸ºçš„äººå‘˜
4. åŸºäºæ­¥éª¤3çš„ç»“æœï¼Œæå–æœ€è¿‘ä¸‰å¹´æœ‰çŠ¯ç½ªè®°å½•çš„äººå‘˜
5. åŸºäºæ­¥éª¤4çš„ç»“æœï¼Œæ ‡æ³¨å‡ºäººå‘˜æˆ·ç±æ‰€å±åŒºå¿

è¯·å‚è€ƒè¿™ä¸ªç¤ºä¾‹çš„åˆ†ææ€è·¯å’Œæ­¥éª¤æ·±åº¦ã€‚"""

            print("ğŸ¤– æ­£åœ¨è°ƒç”¨OpenAI APIè¿›è¡Œæ­¥éª¤åˆ†è§£...")
            
            # è°ƒç”¨OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¡ˆä»¶åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿å°†å¤æ‚æ¡ˆä»¶ç›®æ ‡åˆ†è§£ä¸ºæ¸…æ™°çš„é€»è¾‘æ­¥éª¤ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            print("âœ… OpenAI APIè°ƒç”¨æˆåŠŸ")
            
            ai_response = response.choices[0].message.content
            print(f"ğŸ“ AIå“åº”é•¿åº¦: {len(ai_response)} å­—ç¬¦")
            
            # è§£æAIè¿”å›çš„JSON
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                print("âœ… æ‰¾åˆ°JSONæ ¼å¼å“åº”")
                result = json.loads(json_match.group())
                
                # æ„å»ºåˆ†ææ­¥éª¤ï¼ˆä¸åŒ…å«SQLï¼‰
                steps = []
                if 'steps' in result:
                    for step_data in result['steps']:
                        steps.append(AnalysisStep(
                            step_number=step_data.get('step_number', 0),
                            description=step_data.get('description', '')
                        ))
                
                # åˆ›å»ºå“åº”å¯¹è±¡
                response = CaseDecompositionResponse(
                    steps=steps,
                    summary=result.get('summary', 'æ¡ˆä»¶åˆ†è§£åˆ†æ')
                )
                
                print(f"âœ… æ­¥éª¤åˆ†è§£å®Œæˆï¼Œå…±{len(steps)}ä¸ªæ­¥éª¤")
                return response
                
            else:
                error_msg = "æœªèƒ½ä»AIå“åº”ä¸­è§£æå‡ºæœ‰æ•ˆçš„JSONæ ¼å¼"
                print(f"âŒ {error_msg}")
                print(f"åŸå§‹å“åº”: {ai_response[:500]}...")
                return None
                
        except Exception as e:
            error_msg = f"æ¡ˆä»¶æ­¥éª¤åˆ†è§£å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return None

    def generate_sql_for_steps(self, steps: List[AnalysisStep]) -> Optional[GenerateSQLResponse]:
        """
        æ ¹æ®ç”¨æˆ·è°ƒæ•´åçš„æ­¥éª¤ç”ŸæˆSQL
        
        Args:
            steps: ç”¨æˆ·è°ƒæ•´åçš„æ­¥éª¤åˆ—è¡¨
            
        Returns:
            GenerateSQLResponse: åŒ…å«SQLçš„å®Œæ•´æ­¥éª¤
        """
        try:
            print(f"ğŸ” å¼€å§‹ä¸º{len(steps)}ä¸ªæ­¥éª¤ç”ŸæˆSQL")
            
            if not self.client:
                error_msg = "OpenAI API Key æœªé…ç½®ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡"
                print(f"âŒ {error_msg}")
                raise Exception(error_msg)
            
            # æ„å»ºæ­¥éª¤æè¿°
            steps_description = "\n".join([f"{step.step_number}. {step.description}" for step in steps])
            
            # æ„å»ºSQLç”Ÿæˆæç¤ºè¯
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ“…é•¿SQLç”Ÿæˆçš„å¤§æ¨¡å‹åŠæ¡ˆåŠ©æ‰‹ã€‚

è¯·æ ¹æ®ä»¥ä¸‹å·²ç»ç¡®å®šçš„é€»è¾‘æ­¥éª¤ï¼Œä¸ºæ¯ä¸ªæ­¥éª¤ç”Ÿæˆå¯¹åº”çš„SQLè¯­å¥ã€‚

ã€å·²ç¡®å®šçš„é€»è¾‘æ­¥éª¤ã€‘ï¼š
{steps_description}

ã€SQLç”Ÿæˆè¦æ±‚ã€‘ï¼š
1. ä¸ºæ¯ä¸ªæ­¥éª¤ç”Ÿæˆå¯¹åº”çš„SQLè¯­å¥
2. SQLä¸­ä½¿ç”¨ä¼ªå­—æ®µåå’Œä¼ªè¡¨åï¼Œæ–¹ä¾¿åç»­åšå­—æ®µæ›¿æ¢
3. æ—¶é—´æ¡ä»¶è¯·å°½å¯èƒ½ç”¨ NOW() æˆ–è€… DATE_SUB() è¡¨è¾¾
4. æ‰€æœ‰å­—æ®µå°½é‡ä½¿ç”¨è‹±æ–‡åå¹¶æ³¨é‡Šè¯´æ˜å«ä¹‰
5. ä¸å¿…è€ƒè™‘å…·ä½“æ•°æ®åº“ç±»å‹ï¼Œä¿æŒè¯­æ³•é€šç”¨æ€§
6. æ­¥éª¤ä¹‹é—´çš„SQLåº”è¯¥æœ‰é€»è¾‘å…³è”ï¼Œåç»­æ­¥éª¤å¯ä»¥å¼•ç”¨å‰é¢æ­¥éª¤çš„ç»“æœ

è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "summary": "SQLç”Ÿæˆæ€»ç»“ï¼Œç®€è¦è¯´æ˜å„æ­¥éª¤SQLçš„å…³è”å…³ç³»",
  "steps": [
    {{
      "step_number": 1,
      "description": "{steps[0].description if steps else 'æ­¥éª¤æè¿°'}",
      "sql": "-- æ­¥éª¤1å¯¹åº”çš„SQLä»£ç \\nSELECT..."
    }}
  ]
}}"""

            print("ğŸ¤– æ­£åœ¨è°ƒç”¨OpenAI APIç”ŸæˆSQL...")
            
            # è°ƒç”¨OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„SQLç”ŸæˆåŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®ä¸šåŠ¡é€»è¾‘æ­¥éª¤ç”Ÿæˆå¯¹åº”çš„SQLæŸ¥è¯¢è¯­å¥ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000
            )
            
            print("âœ… OpenAI APIè°ƒç”¨æˆåŠŸ")
            
            ai_response = response.choices[0].message.content
            print(f"ğŸ“ AIå“åº”é•¿åº¦: {len(ai_response)} å­—ç¬¦")
            
            # è§£æAIè¿”å›çš„JSON
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                print("âœ… æ‰¾åˆ°JSONæ ¼å¼å“åº”")
                result = json.loads(json_match.group())
                
                # æ„å»ºåŒ…å«SQLçš„å®Œæ•´æ­¥éª¤
                sql_steps = []
                if 'steps' in result:
                    for i, step in enumerate(steps):
                        # æ‰¾åˆ°å¯¹åº”çš„SQL
                        sql = ""
                        for step_data in result['steps']:
                            if step_data.get('step_number', 0) == step.step_number:
                                sql = step_data.get('sql', '')
                                break
                        
                        sql_steps.append(AnalysisStep(
                            step_number=step.step_number,
                            description=step.description,
                            sql=sql
                        ))
                
                # åˆ›å»ºå“åº”å¯¹è±¡
                response = GenerateSQLResponse(
                    steps=sql_steps,
                    summary=result.get('summary', 'SQLç”Ÿæˆå®Œæˆ')
                )
                
                print(f"âœ… SQLç”Ÿæˆå®Œæˆ")
                return response
                
            else:
                error_msg = "æœªèƒ½ä»AIå“åº”ä¸­è§£æå‡ºæœ‰æ•ˆçš„JSONæ ¼å¼"
                print(f"âŒ {error_msg}")
                print(f"åŸå§‹å“åº”: {ai_response[:500]}...")
                return None
                
        except Exception as e:
            error_msg = f"SQLç”Ÿæˆå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return None
    
    def parse_etl_script(self, etl_file_path: str) -> Optional[Dict]:
        """
        ä½¿ç”¨LLMè§£æETLè„šæœ¬ï¼Œè·å–æ¥æºè¡¨ä¿¡æ¯å’Œä¸šåŠ¡é€»è¾‘æè¿°
        
        Args:
            etl_file_path: ETLè„šæœ¬æ–‡ä»¶è·¯å¾„
            
        Returns:
            DictåŒ…å«: source_tables_info, business_logic
        """
        try:
            if not self.client:
                raise Exception("OpenAI API Key æœªé…ç½®")
            
            # è¯»å–ETLè„šæœ¬å†…å®¹
            with open(etl_file_path, 'r', encoding='utf-8') as f:
                etl_content = f.read()
            
            # æ„å»ºETLè§£ææç¤ºè¯
            prompt = f"""ä½ æ˜¯ä¸ªæ•°æ®æ²»ç†ä¸“å®¶ï¼Œè¿™ä¸ª ETLè„šæœ¬æè¿°çš„æ˜¯å…¬å…±æ•°æ®çš„åŠ å·¥è¿‡ç¨‹ï¼Œè¯·ä½ ä»”ç»†é˜…è¯»è¿™ä¸ªè„šæœ¬ä¿¡æ¯ï¼Œå‘Šè¯‰æˆ‘
1. æ¥æºè¡¨ä¿¡æ¯ï¼Œæˆ‘éœ€è¦è¡¨ä¸­æ–‡åå’Œè¡¨è‹±æ–‡å
2. è¯·ä»ä¸šåŠ¡äººå‘˜å®¹æ˜“ç†è§£çš„æ–¹å¼ï¼Œè®²è¿°ä¸€ä¸‹è¿™ä¸ªè„šæœ¬çš„åŠ å·¥é€»è¾‘ï¼Œä»¥åŠåŠ å·¥åçš„è¡¨çš„ä½œç”¨

ETLè„šæœ¬å†…å®¹ï¼š
{etl_content}

è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "source_tables": [
    {{
      "table_name_en": "æ¥æºè¡¨è‹±æ–‡å",
      "table_name_cn": "æ¥æºè¡¨ä¸­æ–‡åæˆ–ä¸šåŠ¡æè¿°"
    }}
  ],
  "business_logic": "è¯¦ç»†çš„ä¸šåŠ¡é€»è¾‘æè¿°ï¼Œè¯´æ˜è¿™ä¸ªè„šæœ¬çš„åŠ å·¥è¿‡ç¨‹å’ŒåŠ å·¥åè¡¨çš„ä½œç”¨"
}}

æ³¨æ„ï¼š
1. æ¥æºè¡¨çš„ä¸­æ–‡åè¯·æ ¹æ®è¡¨åå’Œä¸šåŠ¡ä¸Šä¸‹æ–‡è¿›è¡Œåˆç†æ¨æµ‹
2. ä¸šåŠ¡é€»è¾‘æè¿°è¦é€šä¿—æ˜“æ‡‚ï¼Œé¿å…æŠ€æœ¯æœ¯è¯­ï¼Œä¾¿äºä¸šåŠ¡äººå‘˜ç†è§£
3. é‡ç‚¹è¯´æ˜æ•°æ®çš„æ¥æºã€åŠ å·¥è¿‡ç¨‹å’Œæœ€ç»ˆç”¨é€”"""

            # è°ƒç”¨OpenAI APIè§£æETL
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®æ²»ç†ä¸“å®¶ï¼Œæ“…é•¿åˆ†æETLè„šæœ¬å¹¶æå–ä¸šåŠ¡é€»è¾‘ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            ai_response = response.choices[0].message.content
            
            # è§£æAIè¿”å›çš„JSON
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result
            else:
                print(f"AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æJSON: {ai_response}")
                return None
                
        except Exception as e:
            print(f"ETLè„šæœ¬è§£æå¤±è´¥: {str(e)}")
            return None

    def generate_catalog_info(self, table_name: str) -> Optional[CatalogInfo]:
        """
        æ ¹æ®è¡¨åè‡ªåŠ¨ç”Ÿæˆç¼–ç›®ä¿¡æ¯
        
        Args:
            table_name: è¡¨å
            
        Returns:
            CatalogInfo: ç”Ÿæˆçš„ç¼–ç›®ä¿¡æ¯
        """
        try:
            # æ£€æŸ¥API Keyæ˜¯å¦å¯ç”¨
            if not self.client:
                raise Exception("OpenAI API Key æœªé…ç½®ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            
            # è·å–è¡¨çš„è¯¦ç»†ä¿¡æ¯
            table_detail = self.table_service.get_table_detail(table_name)
            if not table_detail:
                raise Exception(f"è¡¨ {table_name} ä¸å­˜åœ¨æˆ–æ— æ³•è§£æ")
            
            # è·å–ETLä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            etl_info = None
            etl_file_path = self.table_service.sql_parser.get_etl_file_path(table_name)
            if etl_file_path:
                # ä½¿ç”¨LLMè§£æETLè„šæœ¬
                etl_info = self.parse_etl_script(etl_file_path)
            
            # æ„å»ºæç¤ºè¯
            prompt = self._build_analysis_prompt(table_detail, etl_info)
            
            # è°ƒç”¨OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®æ²»ç†ä¸“å®¶ï¼Œæ“…é•¿åˆ†ææ•°æ®è¡¨ç»“æ„å¹¶ç”Ÿæˆç¼–ç›®ä¿¡æ¯ã€‚è¯·æ ¹æ®æä¾›çš„è¡¨ç»“æ„ä¿¡æ¯ï¼Œç”Ÿæˆåˆé€‚çš„ç¼–ç›®å…ƒæ•°æ®ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            # è§£æAIå“åº”
            ai_analysis = response.choices[0].message.content
            
            # æ„å»ºç¼–ç›®ä¿¡æ¯
            catalog_info = self._build_catalog_info(table_detail, etl_info, ai_analysis)
            
            return catalog_info
            
        except Exception as e:
            error_msg = str(e)
            if "OpenAI API Key" in error_msg:
                print(f"AIç¼–ç›®åŠŸèƒ½éœ€è¦é…ç½®API Key: {error_msg}")
            elif "è¡¨" in error_msg and "ä¸å­˜åœ¨" in error_msg:
                print(f"è¡¨è§£æå¤±è´¥: {error_msg}")
            else:
                print(f"AIç”Ÿæˆç¼–ç›®ä¿¡æ¯å¤±è´¥: {error_msg}")
            return None
    
    def _build_analysis_prompt(self, table_detail, etl_info) -> str:
        """æ„å»ºAIåˆ†ææç¤ºè¯"""
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ•°æ®è¡¨çš„ç»“æ„ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆç¼–ç›®å…ƒæ•°æ®ï¼š

è¡¨å: {table_detail.table_name_en}
è¡¨æ³¨é‡Š: {table_detail.table_name_cn}
æ•°æ®åˆ†å±‚: {table_detail.layer.value}

å­—æ®µä¿¡æ¯:
"""
        
        for field in table_detail.fields:
            prompt += f"- {field.field_name_en} ({field.field_type}): {field.field_name_cn}\n"
        
        if etl_info:
            prompt += f"\nåŠ å·¥ä¿¡æ¯:\n"
            prompt += f"- æ˜¯å¦ä¸ºåŠ å·¥è¡¨: æ˜¯\n"
            if etl_info.get('source_tables'):
                prompt += f"- æ¥æºè¡¨ä¿¡æ¯:\n"
                for source_table in etl_info['source_tables']:
                    prompt += f"  * {source_table['table_name_en']}: {source_table['table_name_cn']}\n"
            prompt += f"- ä¸šåŠ¡é€»è¾‘: {etl_info.get('business_logic', 'æœªçŸ¥')}\n"
        else:
            prompt += f"\nåŠ å·¥ä¿¡æ¯:\n- æ˜¯å¦ä¸ºåŠ å·¥è¡¨: å¦\n"
        
        prompt += """

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œåˆ†æå¹¶è¿”å›ä»¥ä¸‹å†…å®¹ï¼ˆç”¨JSONæ ¼å¼ï¼‰ï¼š

{
  "resource_summary": "ä¸€å¥è¯æ¦‚æ‹¬è¡¨çš„åŠŸèƒ½å’Œç”¨é€”",
  "domain_category": "é€‰æ‹©åˆé€‚çš„é¢†åŸŸåˆ†ç±»: ä¼ä¸šç›‘ç®¡|äººå£ç®¡ç†|åœ°ç†ä¿¡æ¯|é‡‘èç›‘ç®¡|åŒ»ç–—å«ç”Ÿ|æ•™è‚²ç®¡ç†|äº¤é€šè¿è¾“|ç¯å¢ƒä¿æŠ¤|å†œä¸šå†œæ‘|å¸æ³•æ‰§æ³•|å…¶ä»–",
  "organization_name": "æ ¹æ®è¡¨åå’Œå­—æ®µæ¨æ–­æ‰€å±çš„å±€å§”åŠåç§°",
  "irs_system_name": "æ¨æ–­æ‰€å±çš„ä¸šåŠ¡ç³»ç»Ÿåç§°"
}

åˆ†æè¦ç‚¹:
1. æ ¹æ®è¡¨åå‰ç¼€(ads/dwd/ods/stg)ç¡®å®šæ•°æ®åˆ†å±‚
2. æ ¹æ®å­—æ®µå†…å®¹åˆ¤æ–­ä¸šåŠ¡é¢†åŸŸ
3. æ ¹æ®è¡¨åå’Œå­—æ®µæ¨æ–­æ”¿åºœéƒ¨é—¨å½’å±
4. ç”Ÿæˆç®€æ´å‡†ç¡®çš„è¡¨åŠŸèƒ½æè¿°
"""
        
        return prompt
    
    def _build_catalog_info(self, table_detail, etl_info, ai_analysis: str) -> CatalogInfo:
        """æ ¹æ®AIåˆ†æç»“æœæ„å»ºç¼–ç›®ä¿¡æ¯"""
        # å°è¯•ä»AIå“åº”ä¸­æå–JSON
        try:
            # æŸ¥æ‰¾JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', ai_analysis, re.DOTALL)
            if json_match:
                ai_data = json.loads(json_match.group())
            else:
                ai_data = {}
        except:
            ai_data = {}
        
        # å¤„ç†æ¥æºè¡¨ä¿¡æ¯
        source_tables = None
        if etl_info and etl_info.get('source_tables'):
            source_tables = []
            for source_table_info in etl_info['source_tables']:
                source_tables.append(SourceTableInfo(
                    table_name_en=source_table_info['table_name_en'],
                    table_name_cn=source_table_info['table_name_cn']
                ))
        
        # å¤„ç†é¢†åŸŸåˆ†ç±»
        domain_category = DomainCategory.OTHER
        if 'domain_category' in ai_data:
            category_mapping = {
                "ä¼ä¸šç›‘ç®¡": DomainCategory.ENTERPRISE,
                "äººå£ç®¡ç†": DomainCategory.POPULATION,
                "åœ°ç†ä¿¡æ¯": DomainCategory.GEOGRAPHIC,
                "é‡‘èç›‘ç®¡": DomainCategory.FINANCIAL,
                "åŒ»ç–—å«ç”Ÿ": DomainCategory.HEALTH,
                "æ•™è‚²ç®¡ç†": DomainCategory.EDUCATION,
                "äº¤é€šè¿è¾“": DomainCategory.TRANSPORTATION,
                "ç¯å¢ƒä¿æŠ¤": DomainCategory.ENVIRONMENT,
                "å†œä¸šå†œæ‘": DomainCategory.AGRICULTURE,
                "å¸æ³•æ‰§æ³•": DomainCategory.JUSTICE
            }
            domain_category = category_mapping.get(ai_data['domain_category'], DomainCategory.OTHER)
        
        return CatalogInfo(
            table_name_en=table_detail.table_name_en,
            resource_name=table_detail.table_name_cn,
            resource_summary=ai_data.get('resource_summary', f"{table_detail.table_name_cn}ç›¸å…³æ•°æ®è¡¨"),
            resource_format="table",
            domain_category=domain_category,
            organization_name=ai_data.get('organization_name', "æœªçŸ¥æœºæ„"),
            irs_system_name=ai_data.get('irs_system_name', "ä¸šåŠ¡ç³»ç»Ÿ"),
            layer=table_detail.layer,
            fields=table_detail.fields,
            is_processed=etl_info is not None,
            source_tables=source_tables,
            processing_logic=etl_info.get('business_logic') if etl_info else None
        )
